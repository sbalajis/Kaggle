{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import prettyplotlib as ppl\n",
    "import brewer2mpl\n",
    "import random\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set2 = brewer2mpl.get_map('Set2', 'qualitative', 8).mpl_colors\n",
    "\n",
    "font = {'family' : 'serif',\n",
    "        'color'  : 'darkred',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 16,\n",
    "        }\n",
    "plt.rc('font',family='serif')\n",
    "plt.rc('font', size=16)\n",
    "plt.rc('font', weight='bold')\n",
    "plt.style.use('fivethirtyeight')\n",
    "    \n",
    "# Get current size\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    " \n",
    "# Set figure width to 6 and height to 6\n",
    "fig_size[0] = 6\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/act_train.csv', dtype={'people_id': np.str,\n",
    "                               'activity_id': np.str,\n",
    "                               'outcome': np.int8}, parse_dates=['date'])\n",
    "test = pd.read_csv('data/act_test.csv', dtype={'people_id': np.str,\n",
    "                              'activity_id': np.str}, parse_dates=['date'])\n",
    "people = pd.read_csv('data/people.csv', dtype={'people_id': np.str,\n",
    "                              'activity_id': np.str,\n",
    "                              'char_38': np.int32},parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>people_id</th>\n",
       "      <th>activity_id</th>\n",
       "      <th>date</th>\n",
       "      <th>activity_category</th>\n",
       "      <th>char_1</th>\n",
       "      <th>char_2</th>\n",
       "      <th>char_3</th>\n",
       "      <th>char_4</th>\n",
       "      <th>char_5</th>\n",
       "      <th>char_6</th>\n",
       "      <th>char_7</th>\n",
       "      <th>char_8</th>\n",
       "      <th>char_9</th>\n",
       "      <th>char_10</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_1734928</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 76</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_2434093</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3404049</td>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_3651215</td>\n",
       "      <td>2023-08-04</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl_100</td>\n",
       "      <td>act2_4109017</td>\n",
       "      <td>2023-08-26</td>\n",
       "      <td>type 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>type 1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  people_id   activity_id       date activity_category char_1 char_2 char_3  \\\n",
       "0   ppl_100  act2_1734928 2023-08-26            type 4    NaN    NaN    NaN   \n",
       "1   ppl_100  act2_2434093 2022-09-27            type 2    NaN    NaN    NaN   \n",
       "2   ppl_100  act2_3404049 2022-09-27            type 2    NaN    NaN    NaN   \n",
       "3   ppl_100  act2_3651215 2023-08-04            type 2    NaN    NaN    NaN   \n",
       "4   ppl_100  act2_4109017 2023-08-26            type 2    NaN    NaN    NaN   \n",
       "\n",
       "  char_4 char_5 char_6 char_7 char_8 char_9  char_10  outcome  \n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN  type 76        0  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "2    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "3    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  \n",
       "4    NaN    NaN    NaN    NaN    NaN    NaN   type 1        0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process tables...\n"
     ]
    }
   ],
   "source": [
    "print(\"Process tables...\")\n",
    "for table in [train, test]:\n",
    "        table['year'] = table['date'].dt.year\n",
    "        table['month'] = table['date'].dt.month\n",
    "        table['day'] = table['date'].dt.day\n",
    "        table.drop('date', axis=1, inplace=True)\n",
    "        table['activity_category'] = table['activity_category'].str.lstrip('type ').astype(np.int32)\n",
    "        for i in range(1, 11):\n",
    "            table['char_' + str(i)].fillna('type -999', inplace=True)\n",
    "            table['char_' + str(i)] = table['char_' + str(i)].str.lstrip('type ').astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge...\n"
     ]
    }
   ],
   "source": [
    "people['year'] = people['date'].dt.year\n",
    "people['month'] = people['date'].dt.month\n",
    "people['day'] = people['date'].dt.day\n",
    "people.drop('date', axis=1, inplace=True)\n",
    "people['group_1'] = people['group_1'].str.lstrip('group ').astype(np.int32)\n",
    "for i in range(1, 10):\n",
    "        people['char_' + str(i)] = people['char_' + str(i)].str.lstrip('type ').astype(np.int32)\n",
    "for i in range(10, 38):\n",
    "        people['char_' + str(i)] = people['char_' + str(i)].astype(np.int32)\n",
    "\n",
    "print(\"Merge...\")\n",
    "train = pd.merge(train, people, how='left', on='people_id', left_index=True)\n",
    "train.fillna(-999, inplace=True)\n",
    "test = pd.merge(test, people, how='left', on='people_id', left_index=True)\n",
    "test.fillna(-999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_cols = [col for col in train.columns if col not in ['people_id', 'activity_id','outcome']]\n",
    "target = 'outcome'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train:  2197291\n",
      "Length of test:  498687\n",
      "Features [56]: ['activity_category', 'char_10_x', 'char_10_y', 'char_11', 'char_12', 'char_13', 'char_14', 'char_15', 'char_16', 'char_17', 'char_18', 'char_19', 'char_1_x', 'char_1_y', 'char_20', 'char_21', 'char_22', 'char_23', 'char_24', 'char_25', 'char_26', 'char_27', 'char_28', 'char_29', 'char_2_x', 'char_2_y', 'char_30', 'char_31', 'char_32', 'char_33', 'char_34', 'char_35', 'char_36', 'char_37', 'char_38', 'char_3_x', 'char_3_y', 'char_4_x', 'char_4_y', 'char_5_x', 'char_5_y', 'char_6_x', 'char_6_y', 'char_7_x', 'char_7_y', 'char_8_x', 'char_8_y', 'char_9_x', 'char_9_y', 'day_x', 'day_y', 'group_1', 'month_x', 'month_y', 'year_x', 'year_y']\n"
     ]
    }
   ],
   "source": [
    "print('Length of train: ', len(train))\n",
    "print('Length of test: ', len(test))\n",
    "print('Features [{}]: {}'.format(len(feature_cols), sorted(feature_cols)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i, feat))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_importance(gbm, features):\n",
    "    create_feature_map(features)\n",
    "    importance = gbm.get_fscore(fmap='xgb.fmap')\n",
    "    importance = sorted(importance.items(), key=itemgetter(1), reverse=True)\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_single(train, test, features, target, random_state=0):\n",
    "    eta = 0.2\n",
    "    max_depth = 5\n",
    "    subsample = 0.8\n",
    "    colsample_bytree = 0.8\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, max_depth, subsample, colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"tree_method\": 'exact',\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"seed\": random_state,\n",
    "    }\n",
    "    num_boost_round = 115\n",
    "    early_stopping_rounds = 10\n",
    "    test_size = 0.1\n",
    "\n",
    "    X_train, X_valid = train_test_split(train, test_size=test_size, random_state=random_state)\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length valid:', len(X_valid.index))\n",
    "    y_train = X_train[target]\n",
    "    y_valid = X_valid[target]\n",
    "    dtrain = xgb.DMatrix(X_train[features], y_train)\n",
    "    dvalid = xgb.DMatrix(X_valid[features], y_valid)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(params, dtrain, num_boost_round, evals=watchlist, early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "    print(\"Validating...\")\n",
    "    check = gbm.predict(xgb.DMatrix(X_valid[features]), ntree_limit=gbm.best_iteration+1)\n",
    "    score = roc_auc_score(X_valid[target].values, check)\n",
    "    print('Check error value: {:.6f}'.format(score))\n",
    "\n",
    "    imp = get_importance(gbm, features)\n",
    "    print('Importance array: ', imp)\n",
    "\n",
    "    print(\"Predict test set...\")\n",
    "    test_prediction = gbm.predict(xgb.DMatrix(test[features]), ntree_limit=gbm.best_iteration+1)\n",
    "\n",
    "    print('Training time: {} minutes'.format(round((time.time() - start_time)/60, 2)))\n",
    "    return test_prediction.tolist(), score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost params. ETA: 0.2, MAX_DEPTH: 5, SUBSAMPLE: 0.8, COLSAMPLE_BY_TREE: 0.8\n",
      "Length train:"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Will train until eval error hasn't decreased in 10 rounds.\n",
      "[0]\ttrain-auc:0.907602\teval-auc:0.907374\n",
      "[1]\ttrain-auc:0.913504\teval-auc:0.913421\n",
      "[2]\ttrain-auc:0.924558\teval-auc:0.924228\n",
      "[3]\ttrain-auc:0.927926\teval-auc:0.927518\n",
      "[4]\ttrain-auc:0.929106\teval-auc:0.928761\n",
      "[5]\ttrain-auc:0.929533\teval-auc:0.929015\n",
      "[6]\ttrain-auc:0.929751\teval-auc:0.929260\n",
      "[7]\ttrain-auc:0.930174\teval-auc:0.929591\n",
      "[8]\ttrain-auc:0.930535\teval-auc:0.929916\n",
      "[9]\ttrain-auc:0.930653\teval-auc:0.930069\n",
      "[10]\ttrain-auc:0.931911\teval-auc:0.931246\n",
      "[11]\ttrain-auc:0.932197\teval-auc:0.931533\n",
      "[12]\ttrain-auc:0.933671\teval-auc:0.933043\n",
      "[13]\ttrain-auc:0.934529\teval-auc:0.933922\n",
      "[14]\ttrain-auc:0.935246\teval-auc:0.934619\n",
      "[15]\ttrain-auc:0.936155\teval-auc:0.935594\n",
      "[16]\ttrain-auc:0.936445\teval-auc:0.935894\n",
      "[17]\ttrain-auc:0.936629\teval-auc:0.936072\n",
      "[18]\ttrain-auc:0.937377\teval-auc:0.936798\n",
      "[19]\ttrain-auc:0.937730\teval-auc:0.937151\n",
      "[20]\ttrain-auc:0.938241\teval-auc:0.937686\n",
      "[21]\ttrain-auc:0.938755\teval-auc:0.938209\n",
      "[22]\ttrain-auc:0.939387\teval-auc:0.938847\n",
      "[23]\ttrain-auc:0.939718\teval-auc:0.939155\n",
      "[24]\ttrain-auc:0.940269\teval-auc:0.939705\n",
      "[25]\ttrain-auc:0.940493\teval-auc:0.939927\n",
      "[26]\ttrain-auc:0.940518\teval-auc:0.939960\n",
      "[27]\ttrain-auc:0.940750\teval-auc:0.940275\n",
      "[28]\ttrain-auc:0.941087\teval-auc:0.940637\n",
      "[29]\ttrain-auc:0.941188\teval-auc:0.940724\n",
      "[30]\ttrain-auc:0.941740\teval-auc:0.941274\n",
      "[31]\ttrain-auc:0.942149\teval-auc:0.941665\n",
      "[32]\ttrain-auc:0.942547\teval-auc:0.942047\n",
      "[33]\ttrain-auc:0.942938\teval-auc:0.942438\n",
      "[34]\ttrain-auc:0.943611\teval-auc:0.943169\n",
      "[35]\ttrain-auc:0.943773\teval-auc:0.943344\n",
      "[36]\ttrain-auc:0.943831\teval-auc:0.943408\n",
      "[37]\ttrain-auc:0.944933\teval-auc:0.944527\n",
      "[38]\ttrain-auc:0.945293\teval-auc:0.944896\n",
      "[39]\ttrain-auc:0.945708\teval-auc:0.945308\n",
      "[40]\ttrain-auc:0.946281\teval-auc:0.945876\n",
      "[41]\ttrain-auc:0.946530\teval-auc:0.946116\n",
      "[42]\ttrain-auc:0.946851\teval-auc:0.946441\n",
      "[43]\ttrain-auc:0.947192\teval-auc:0.946814\n",
      "[44]\ttrain-auc:0.947477\teval-auc:0.947112\n",
      "[45]\ttrain-auc:0.947619\teval-auc:0.947261\n",
      "[46]\ttrain-auc:0.948053\teval-auc:0.947685\n",
      "[47]\ttrain-auc:0.948119\teval-auc:0.947755\n",
      "[48]\ttrain-auc:0.948392\teval-auc:0.948044\n",
      "[49]\ttrain-auc:0.948702\teval-auc:0.948342\n",
      "[50]\ttrain-auc:0.948768\teval-auc:0.948416\n",
      "[51]\ttrain-auc:0.949061\teval-auc:0.948715\n",
      "[52]\ttrain-auc:0.949544\teval-auc:0.949160\n",
      "[53]\ttrain-auc:0.949854\teval-auc:0.949477\n",
      "[54]\ttrain-auc:0.950261\teval-auc:0.949869\n",
      "[55]\ttrain-auc:0.950565\teval-auc:0.950139\n",
      "[56]\ttrain-auc:0.950622\teval-auc:0.950239\n",
      "[57]\ttrain-auc:0.950706\teval-auc:0.950329\n",
      "[58]\ttrain-auc:0.950962\teval-auc:0.950566\n",
      "[59]\ttrain-auc:0.951273\teval-auc:0.950858\n",
      "[60]\ttrain-auc:0.951872\teval-auc:0.951468\n",
      "[61]\ttrain-auc:0.952354\teval-auc:0.951990\n",
      "[62]\ttrain-auc:0.952888\teval-auc:0.952525\n",
      "[63]\ttrain-auc:0.952931\teval-auc:0.952569\n",
      "[64]\ttrain-auc:0.953283\teval-auc:0.952917\n",
      "[65]\ttrain-auc:0.953428\teval-auc:0.953073\n",
      "[66]\ttrain-auc:0.954109\teval-auc:0.953667\n",
      "[67]\ttrain-auc:0.954678\teval-auc:0.954180\n",
      "[68]\ttrain-auc:0.954820\teval-auc:0.954308\n",
      "[69]\ttrain-auc:0.955091\teval-auc:0.954547\n",
      "[70]\ttrain-auc:0.955158\teval-auc:0.954618\n",
      "[71]\ttrain-auc:0.955297\teval-auc:0.954756\n",
      "[72]\ttrain-auc:0.955482\teval-auc:0.954952\n",
      "[73]\ttrain-auc:0.955797\teval-auc:0.955264\n",
      "[74]\ttrain-auc:0.956071\teval-auc:0.955514\n",
      "[75]\ttrain-auc:0.956406\teval-auc:0.955855\n",
      "[76]\ttrain-auc:0.956612\teval-auc:0.956054\n",
      "[77]\ttrain-auc:0.956897\teval-auc:0.956368\n",
      "[78]\ttrain-auc:0.957009\teval-auc:0.956471\n",
      "[79]\ttrain-auc:0.957099\teval-auc:0.956564\n",
      "[80]\ttrain-auc:0.957366\teval-auc:0.956868\n",
      "[81]\ttrain-auc:0.957732\teval-auc:0.957240\n",
      "[82]\ttrain-auc:0.958073\teval-auc:0.957576\n",
      "[83]\ttrain-auc:0.958100\teval-auc:0.957597\n",
      "[84]\ttrain-auc:0.958413\teval-auc:0.957908\n",
      "[85]\ttrain-auc:0.958454\teval-auc:0.957945\n",
      "[86]\ttrain-auc:0.958680\teval-auc:0.958186\n",
      "[87]\ttrain-auc:0.958849\teval-auc:0.958336\n",
      "[88]\ttrain-auc:0.959009\teval-auc:0.958460\n",
      "[89]\ttrain-auc:0.959240\teval-auc:0.958684\n",
      "[90]\ttrain-auc:0.959355\teval-auc:0.958817\n",
      "[91]\ttrain-auc:0.959372\teval-auc:0.958835\n",
      "[92]\ttrain-auc:0.959480\teval-auc:0.958944\n",
      "[93]\ttrain-auc:0.959902\teval-auc:0.959387\n",
      "[94]\ttrain-auc:0.960167\teval-auc:0.959640\n",
      "[95]\ttrain-auc:0.960224\teval-auc:0.959691\n",
      "[96]\ttrain-auc:0.960264\teval-auc:0.959729\n",
      "[97]\ttrain-auc:0.960674\teval-auc:0.960127\n",
      "[98]\ttrain-auc:0.960859\teval-auc:0.960297\n",
      "[99]\ttrain-auc:0.961012\teval-auc:0.960454\n",
      "[100]\ttrain-auc:0.961207\teval-auc:0.960649\n",
      "[101]\ttrain-auc:0.961379\teval-auc:0.960808\n",
      "[102]\ttrain-auc:0.961513\teval-auc:0.960942\n",
      "[103]\ttrain-auc:0.961605\teval-auc:0.961030\n",
      "[104]\ttrain-auc:0.961805\teval-auc:0.961221\n",
      "[105]\ttrain-auc:0.961966\teval-auc:0.961400\n",
      "[106]\ttrain-auc:0.962203\teval-auc:0.961682\n",
      "[107]\ttrain-auc:0.962222\teval-auc:0.961712\n",
      "[108]\ttrain-auc:0.962346\teval-auc:0.961814\n",
      "[109]\ttrain-auc:0.962446\teval-auc:0.961918\n",
      "[110]\ttrain-auc:0.962679\teval-auc:0.962165\n",
      "[111]\ttrain-auc:0.962948\teval-auc:0.962427\n",
      "[112]\ttrain-auc:0.963156\teval-auc:0.962632\n",
      "[113]\ttrain-auc:0.963253\teval-auc:0.962732\n",
      "[114]\ttrain-auc:0.963340\teval-auc:0.962806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1977561\n",
      "Length valid: 219730\n",
      "Validating...\n",
      "Check error value: 0.962806\n",
      "Importance array:  [('group_1', 831), ('char_38', 346), ('char_7_y', 330), ('char_6_y', 168), ('day_y', 160), ('char_9_y', 128), ('char_8_y', 111), ('month_y', 89), ('char_3_y', 87), ('char_10_x', 80), ('char_4_y', 75), ('year_x', 57), ('year_y', 55), ('month_x', 54), ('char_5_y', 50), ('char_25', 43), ('char_10_y', 41), ('char_2_y', 38), ('char_29', 34), ('char_20', 33), ('char_33', 31), ('char_11', 30), ('day_x', 29), ('char_1_y', 29), ('char_13', 29), ('char_23', 20), ('char_26', 20), ('char_35', 20), ('char_19', 19), ('char_24', 19), ('char_18', 18), ('char_30', 18), ('char_31', 17), ('char_34', 16), ('char_27', 16), ('char_36', 15), ('char_32', 14), ('char_14', 13), ('char_37', 13), ('activity_category', 12), ('char_17', 11), ('char_16', 9), ('char_21', 9), ('char_28', 9), ('char_12', 8), ('char_22', 8), ('char_15', 7), ('char_9_x', 6), ('char_2_x', 3), ('char_8_x', 2), ('char_7_x', 2), ('char_3_x', 2), ('char_6_x', 1), ('char_1_x', 1), ('char_5_x', 1)]\n",
      "Predict test set...\n",
      "Training time: 1.77 minutes\n"
     ]
    }
   ],
   "source": [
    "test_prediction, score = run_single(train, test, feature_cols, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_submission(test, prediction):\n",
    "    now = datetime.datetime.now()\n",
    "    sub_file = 'submission_xg_' + str(now.strftime(\"%Y-%m-%d-%H-%M\")) + '.csv'\n",
    "    print('Writing submission: ', sub_file)\n",
    "    f = open(sub_file, 'w')\n",
    "    f.write('activity_id,outcome\\n')\n",
    "    total = 0\n",
    "    for id in test['activity_id']:\n",
    "        str1 = str(id) + ',' + str(prediction[total])\n",
    "        str1 += '\\n'\n",
    "        total += 1\n",
    "        f.write(str1)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission:  submission_xg_2016-08-14-12-19.csv\n"
     ]
    }
   ],
   "source": [
    "create_submission(test, test_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
